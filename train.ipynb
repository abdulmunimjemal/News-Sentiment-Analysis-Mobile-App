{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/abdulmunim/.cache/pypoetry/virtualenvs/flutter_news_sentiment_analysis_app-OPL5U8Ch-py3.10/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (165 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/abdulmunim/.cache/pypoetry/virtualenvs/flutter_news_sentiment_analysis_app-OPL5U8Ch-py3.10/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-24.12.23-py2.py3-none-any.whl.metadata (876 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in /home/abdulmunim/.cache/pypoetry/virtualenvs/flutter_news_sentiment_analysis_app-OPL5U8Ch-py3.10/lib/python3.10/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/abdulmunim/.cache/pypoetry/virtualenvs/flutter_news_sentiment_analysis_app-OPL5U8Ch-py3.10/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/abdulmunim/.cache/pypoetry/virtualenvs/flutter_news_sentiment_analysis_app-OPL5U8Ch-py3.10/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/abdulmunim/.cache/pypoetry/virtualenvs/flutter_news_sentiment_analysis_app-OPL5U8Ch-py3.10/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "Using cached matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "Using cached numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "Using cached scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached flatbuffers-24.12.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached fonttools-4.55.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.68.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "Using cached h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached keras-3.7.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Using cached protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (381 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, namex, libclang, flatbuffers, wrapt, wheel, urllib3, tzdata, tqdm, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, regex, pyparsing, protobuf, pillow, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, kiwisolver, joblib, idna, grpcio, google-pasta, gast, fonttools, cycler, click, charset-normalizer, certifi, absl-py, werkzeug, scipy, requests, pandas, nltk, ml-dtypes, markdown-it-py, h5py, contourpy, astunparse, tensorboard, scikit-learn, rich, matplotlib, keras, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2024.12.14 charset-normalizer-3.4.1 click-8.1.8 contourpy-1.3.1 cycler-0.12.1 flatbuffers-24.12.23 fonttools-4.55.3 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.1 h5py-3.12.1 idna-3.10 joblib-1.4.2 keras-3.7.0 kiwisolver-1.4.8 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 nltk-3.9.1 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 pandas-2.2.3 pillow-11.1.0 protobuf-5.29.2 pyparsing-3.2.1 pytz-2024.2 regex-2024.11.6 requests-2.32.3 rich-13.9.4 scikit-learn-1.6.0 scipy-1.14.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0 threadpoolctl-3.5.0 tqdm-4.67.1 tzdata-2024.2 urllib3-2.3.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.0\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas numpy matplotlib nltk tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 12:26:24.719769: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-03 12:26:24.830723: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-03 12:26:24.953591: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735896385.067981  474700 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735896385.097663  474700 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-03 12:26:25.296913: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt_data = pd.read_csv(\"dataset/AMT_Clean.csv\")\n",
    "r_data = pd.read_csv(\"dataset/R_Clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>entity</th>\n",
       "      <th>majority_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Russia and Poland Feud Over Putin Remarks on W...</td>\n",
       "      <td>Putin</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Trump Moves to Lift Visa Restrictions on Polis...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Trump-Backed U.S.-British Trade Deal Faces Hur...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Trump’s Arrival in London Brings Controversy b...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Trump Steers Clear of War Footing Toward Iran</td>\n",
       "      <td>Trump</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline entity  \\\n",
       "0           0  Russia and Poland Feud Over Putin Remarks on W...  Putin   \n",
       "1           1  Trump Moves to Lift Visa Restrictions on Polis...  Trump   \n",
       "2           2  Trump-Backed U.S.-British Trade Deal Faces Hur...  Trump   \n",
       "3           3  Trump’s Arrival in London Brings Controversy b...  Trump   \n",
       "4           4      Trump Steers Clear of War Footing Toward Iran  Trump   \n",
       "\n",
       "  majority_label  \n",
       "0       Negative  \n",
       "1        Neutral  \n",
       "2        Neutral  \n",
       "3       Negative  \n",
       "4        Neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amt_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map_amt = {\n",
    "    \"Negative\": 2,\n",
    "    \"Neutral\": 0,\n",
    "    \"Positive\": 1\n",
    "}\n",
    "\n",
    "amt_data['tag'] = amt_data['majority_label'].map(labels_map_amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>entity</th>\n",
       "      <th>majority_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Boris Johnson Joins Trump in Redefining Conser...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>neutr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Trump Praises Controversial Hungarian Leader</td>\n",
       "      <td>Trump</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Stung by Trump’s Criticisms of Russian Gas Dea...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>neutr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What ‘America First’ Means Under Trump Is Comi...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>neutr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Trump Set to Meet With Russia’s Top Diplomat T...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>neutr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Trump Clashes With Macron on NATO, Trade and I...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>neutr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Donald Trump Won’t Slow Efforts to Fight Clima...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Trump to Attend NATO Summit in London</td>\n",
       "      <td>Trump</td>\n",
       "      <td>neutr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Trump-Erdogan Rapport Tested by Tensions Over ...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>neutr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Trump Says Erdogan Visit to U.S. Is On U.S. Of...</td>\n",
       "      <td>Trump</td>\n",
       "      <td>neutr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline entity  \\\n",
       "0           0  Boris Johnson Joins Trump in Redefining Conser...  Trump   \n",
       "1           1       Trump Praises Controversial Hungarian Leader  Trump   \n",
       "2           2  Stung by Trump’s Criticisms of Russian Gas Dea...  Trump   \n",
       "3           3  What ‘America First’ Means Under Trump Is Comi...  Trump   \n",
       "4           4  Trump Set to Meet With Russia’s Top Diplomat T...  Trump   \n",
       "5           5  Trump Clashes With Macron on NATO, Trade and I...  Trump   \n",
       "6           6  Donald Trump Won’t Slow Efforts to Fight Clima...  Trump   \n",
       "7           7              Trump to Attend NATO Summit in London  Trump   \n",
       "8           8  Trump-Erdogan Rapport Tested by Tensions Over ...  Trump   \n",
       "9           9  Trump Says Erdogan Visit to U.S. Is On U.S. Of...  Trump   \n",
       "\n",
       "  majority_label  \n",
       "0          neutr  \n",
       "1            neg  \n",
       "2          neutr  \n",
       "3          neutr  \n",
       "4          neutr  \n",
       "5          neutr  \n",
       "6            pos  \n",
       "7          neutr  \n",
       "8          neutr  \n",
       "9          neutr  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_map = {\n",
    "    \"neg\": 2,\n",
    "    \"neutr\": 0,\n",
    "    \"pos\": 1\n",
    "}\n",
    "r_data['tag'] = r_data['majority_label'].map(r_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the text and labels and merge to one dataframe\n",
    "amt_data = amt_data[['headline', 'tag']]\n",
    "r_data = r_data[['headline', 'tag']]\n",
    "data = pd.concat([amt_data, r_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russia and Poland Feud Over Putin Remarks on W...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump Moves to Lift Visa Restrictions on Polis...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump-Backed U.S.-British Trade Deal Faces Hur...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump’s Arrival in London Brings Controversy b...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump Steers Clear of War Footing Toward Iran</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  tag\n",
       "0  Russia and Poland Feud Over Putin Remarks on W...  2.0\n",
       "1  Trump Moves to Lift Visa Restrictions on Polis...  0.0\n",
       "2  Trump-Backed U.S.-British Trade Deal Faces Hur...  0.0\n",
       "3  Trump’s Arrival in London Brings Controversy b...  2.0\n",
       "4      Trump Steers Clear of War Footing Toward Iran  0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/abdulmunim/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create some more synthetic data by translating the headlines to synonym\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "def replace_synonyms(sentence, n=2):\n",
    "    words = sentence.split()\n",
    "    for _ in range(n):\n",
    "        idx = random.randint(0, len(words) - 1)\n",
    "        synonyms = wordnet.synsets(words[idx])\n",
    "        if synonyms:\n",
    "            synonym = synonyms[0].lemmas()[0].name()\n",
    "            words[idx] = synonym\n",
    "    return ' '.join(words)\n",
    "\n",
    "# add the synthetic data to the dataset\n",
    "synthetic_data = data.copy()\n",
    "synthetic_data['headline'] = synthetic_data['headline'].apply(lambda x: replace_synonyms(x))\n",
    "data = pd.concat([data, synthetic_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install googletrans==4.0.0-rc1\n",
    "# More synthetic data by  back translation\n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "def back_translate(sentence, src='en', intermediate='fr'):\n",
    "    translated = translator.translate(sentence, src=src, dest=intermediate).text\n",
    "    back_translated = translator.translate(translated, src=intermediate, dest=src).text\n",
    "    return back_translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics pof the data\n",
    "data.dropna(inplace=True)\n",
    "data['tag'] = data['tag'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(data['headline'])\n",
    "sequences = tokenizer.texts_to_sequences(data['headline'])\n",
    "padded_sequences = pad_sequences(sequences, padding='post', maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the word index to a JSON file\n",
    "import json\n",
    "with open('word_index.json', 'w') as f:\n",
    "    json.dump(tokenizer.word_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, data['tag'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abdulmunim/.cache/pypoetry/virtualenvs/flutter_news_sentiment_analysis_app-OPL5U8Ch-py3.10/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "2025-01-03 12:27:22.142087: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=24, input_length=100),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(24)),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3913, 100)\n",
      "(3913,)\n",
      "{0, 1, 2}\n",
      "{0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(set(y_train))  # Should print {0, 1, 2}\n",
    "print(set(y_test))   # Should print {0, 1, 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.4377 - loss: 1.0631 - val_accuracy: 0.5332 - val_loss: 1.0321\n",
      "Epoch 2/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.5485 - loss: 0.9609 - val_accuracy: 0.6517 - val_loss: 0.8130\n",
      "Epoch 3/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.7813 - loss: 0.5841 - val_accuracy: 0.7375 - val_loss: 0.6950\n",
      "Epoch 4/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8657 - loss: 0.3897 - val_accuracy: 0.7835 - val_loss: 0.6292\n",
      "Epoch 5/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8979 - loss: 0.2999 - val_accuracy: 0.7732 - val_loss: 0.7541\n",
      "Epoch 6/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9197 - loss: 0.2396 - val_accuracy: 0.7916 - val_loss: 0.6274\n",
      "Epoch 7/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9151 - loss: 0.2310 - val_accuracy: 0.8018 - val_loss: 0.6533\n",
      "Epoch 8/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.9186 - loss: 0.2161 - val_accuracy: 0.7988 - val_loss: 0.6639\n",
      "Epoch 9/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9259 - loss: 0.1856 - val_accuracy: 0.7998 - val_loss: 0.6777\n",
      "Epoch 10/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9315 - loss: 0.1792 - val_accuracy: 0.8018 - val_loss: 0.6747\n",
      "Epoch 11/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9280 - loss: 0.1722 - val_accuracy: 0.7988 - val_loss: 0.6403\n",
      "Epoch 12/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9361 - loss: 0.1557 - val_accuracy: 0.8069 - val_loss: 0.7807\n",
      "Epoch 13/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9203 - loss: 0.1755 - val_accuracy: 0.7906 - val_loss: 0.6989\n",
      "Epoch 14/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9324 - loss: 0.1604 - val_accuracy: 0.8080 - val_loss: 0.7368\n",
      "Epoch 15/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9313 - loss: 0.1547 - val_accuracy: 0.7988 - val_loss: 0.8210\n",
      "Epoch 16/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9369 - loss: 0.1518 - val_accuracy: 0.7978 - val_loss: 0.8489\n",
      "Epoch 17/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9292 - loss: 0.1499 - val_accuracy: 0.8059 - val_loss: 0.8701\n",
      "Epoch 18/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9385 - loss: 0.1369 - val_accuracy: 0.7978 - val_loss: 0.8604\n",
      "Epoch 19/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9270 - loss: 0.1530 - val_accuracy: 0.8039 - val_loss: 1.0175\n",
      "Epoch 20/20\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9322 - loss: 0.1445 - val_accuracy: 0.7988 - val_loss: 0.9842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20\n",
    "                    , validation_data=(X_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/news_sentiment_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/news_sentiment_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'models/news_sentiment_model'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 100), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138715516589456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138715502616016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138715502613200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138715505211904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138715505212256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138715505201168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138715505202576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138715504682336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138715504681456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138715508579440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138715508579792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export(\"models/news_sentiment_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quantize the Model for Mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1735896534.758060  474700 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1735896534.758379  474700 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-01-03 12:28:54.763423: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: models/news_sentiment_model\n",
      "2025-01-03 12:28:54.766679: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-01-03 12:28:54.766724: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: models/news_sentiment_model\n",
      "I0000 00:00:1735896534.792917  474700 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
      "2025-01-03 12:28:54.796883: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-01-03 12:28:54.946945: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: models/news_sentiment_model\n",
      "2025-01-03 12:28:55.004441: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 241005 microseconds.\n",
      "2025-01-03 12:28:55.102349: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-01-03 12:28:55.420862: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3825] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x24xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x24xf32>>>, tensor<i32>, tensor<?x24xf32>) -> (tensor<!tf_type.variant<tensor<?x24xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x24xf32>>>, tensor<2xi32>) -> (tensor<1x?x24xf32>) : {device = \"\", num_elements = 1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"models/news_sentiment_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS    # Enable TensorFlow Select ops.\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open(\"models/news_sentiment_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "INFO: TfLiteFlexDelegate delegate: 3 nodes delegated out of 23 nodes with 2 partitions.\n",
      "\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=\"models/news_sentiment_model.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flutter_news_sentiment_analysis_app-OPL5U8Ch-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
